{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "\n",
    "Перед тем как обучать модель, нужно подготовить для этого данные. \n",
    "\n",
    "Современные нейонные сети, и в особенности генеративные модели, обучаются на очень больших данных. Обработка их с помощью всем известной библиотеки `pandas` затруднительна по ряду причин (нет многопточности, кеширования, неудобный формат хранения, ...)\n",
    "\n",
    "Для работы с большими объемами структурированных данных существует несколько библиотек (`arrow`, `pil`, ...). В этом ноутбуке мы будем использовать библиотеку `datasets` от *hugging-face*, основанную на `arrow`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('csv', \n",
    "    data_files={\n",
    "        'train': ... \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "data = ...  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train'][0:2]  # First two rows of the dataset of type Dict[FeatureName, List[values]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обработка данных осуществляется с помощью 2х основных функций -- `filter` и `map` . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      " \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwith_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0minput_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mremove_columns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mload_from_cache_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcache_file_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwriter_batch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfn_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnum_proc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'DatasetDict'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Apply a filter function to all the elements in the table in batches\n",
      "and update the table so that the dataset only includes examples according to the filter function.\n",
      "The transformation is applied to all the datasets of the dataset dictionary.\n",
      "\n",
      "Args:\n",
      "    function (`callable`): with one of the following signature:\n",
      "        - `function(example: Dict) -> bool` if `with_indices=False`\n",
      "        - `function(example: Dict, indices: int) -> bool` if `with_indices=True`\n",
      "    with_indices (`bool`, defaults to `False`): Provide example indices to `function`. Note that in this case the signature of `function` should be `def function(example, idx): ...`.\n",
      "    input_columns (`Optional[Union[str, List[str]]]`, defaults to `None`): The columns to be passed into `function` as\n",
      "        positional arguments. If `None`, a dict mapping to all formatted columns is passed as one argument.\n",
      "    batch_size (`Optional[int]`, defaults to `1000`): Number of examples per batch provided to `function` if `batched=True`\n",
      "        `batch_size <= 0` or `batch_size == None`: Provide the full dataset as a single batch to `function`\n",
      "    remove_columns (`Optional[List[str]]`, defaults to `None`): Remove a selection of columns while doing the mapping.\n",
      "        Columns will be removed before updating the examples with the output of `function`, i.e. if `function` is adding\n",
      "        columns with names in `remove_columns`, these columns will be kept.\n",
      "    keep_in_memory (`bool`, defaults to `False`): Keep the dataset in memory instead of writing it to a cache file.\n",
      "    load_from_cache_file (`bool`, defaults to `True`): If a cache file storing the current computation from `function`\n",
      "        can be identified, use it instead of recomputing.\n",
      "    cache_file_names (`Optional[Dict[str, str]]`, defaults to `None`): Provide the name of a path for the cache file. It is used to store the\n",
      "        results of the computation instead of the automatically generated cache file name.\n",
      "        You have to provide one :obj:`cache_file_name` per dataset in the dataset dictionary.\n",
      "    writer_batch_size (:obj:`int`, default `1000`): Number of rows per write operation for the cache file writer.\n",
      "        This value is a good trade-off between memory usage during the processing, and processing speed.\n",
      "        Higher value makes the processing do fewer lookups, lower value consume less temporary memory while running `.map()`.\n",
      "    fn_kwargs (`Optional[Dict]`, defaults to `None`): Keyword arguments to be passed to `function`\n",
      "    num_proc (`Optional[int]`, defaults to `None`): Number of processes for multiprocessing. By default it doesn't\n",
      "        use multiprocessing.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Library/Python/3.8/lib/python/site-packages/datasets/dataset_dict.py\n",
      "\u001b[0;31mType:\u001b[0m      method\n"
     ]
    }
   ],
   "source": [
    "? data.filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? data.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только те примеры, где context_1 не пустой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ...  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим каждый пример из датасета к виду одной строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "FIRST_SPEAKER_TOKEN = '@@ПЕРВЫЙ@@'\n",
    "SECOND_SPEAKER_TOKEN = '@@ВТОРОЙ@@'\n",
    "\n",
    "CONTEXT_COLS = ['context_3', 'context_2', 'context_1']\n",
    "RESPONSE_COL = ['response']\n",
    "\n",
    "def convert_to_dialog(example: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "        Convert example row to dialogs str format\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ...\n",
    "\n",
    "assert convert_to_dialog(\n",
    "    {\n",
    "        'context_3': 'привет',\n",
    "        'context_2': 'привет!',\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ") == {'text': '@@ПЕРВЫЙ@@ привет @@ВТОРОЙ@@ привет! @@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}\n",
    "assert convert_to_dialog(\n",
    "    {\n",
    "        'context_1': 'как дела?',\n",
    "        'response': 'супер)'\n",
    "    }\n",
    ") == {'text': '@@ПЕРВЫЙ@@ как дела? @@ВТОРОЙ@@ супер)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ...  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь датасет необходимо токенизировать, точно также как мы это делали при знакомстве с хаггинфейс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('tinkoff-ai/ruDialoGPT-medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def tokenize_example(example: Dict[str, str]):\n",
    "    # YOUR CODE HERE\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ...  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем модель, которую будем обучать, а также вспомогательные классы -- trainer, training_args и datacollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AutoModelForCausalLM.from_pretrained('tinkoff-ai/ruDialoGPT-medium').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываем основные параметры обучения и создаем класс Trainer (https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\n",
    "    'output_dir': './training_output',  # path to save the model's checkpoints\n",
    "    'per_device_train_batch_size': 16,  # batch size per GPU/CPU for training\n",
    "    'gradient_accumulation_steps': 4,  # number of batches to accumulate gradient\n",
    "    'max_steps': 500,  # total number of optimizer.step() calls\n",
    "    'save_steps': 100,  # save every save_steps\n",
    "    'eval_steps': 100,  # run evaluation every eval_steps\n",
    "    'dataloader_num_workers': 0,  # number of workers for data loading (default: 0)\n",
    "    'save_total_limit': 2,  # total number of checkpoints to save, delete older checkpoints when reached\n",
    "}\n",
    "\n",
    "trainer = ... # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пробуем обученный чекпоинт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead\n",
    "\n",
    "checkpoint_path = 'path/to/your/checkpoint-100'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelWithLMHead.from_pretrained(checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef03fb1679aeac65da8746bbb9907ec69320f4b4b60f937c1b2a3f31441eb01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
